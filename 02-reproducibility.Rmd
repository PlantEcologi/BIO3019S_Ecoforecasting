# Reproducible research {#reproducibility}

Before we continue, it's worth highlighting the similarity between the iterative decision making cycle I've outlined in figure \@ref(fig:decisions3) and _the scientific method_, i.e.:

- _Observation > Hypothesis > Experiment > Analyze > Interpret > Report > (Repeat)_

```{r scimethod, echo=FALSE, fig.cap = "_The Scientific Method_ overlain on iterative decision making.", fig.width=3, fig.align = 'center'}
knitr::include_graphics("img/scimethod.png")
```

<br>

It's also worth noting that _reproducibility is one of the fundamental tenets of science_. In other words, published research should be robust enough and the methods described in enough detail that anyone else should be able to repeat the study (using the publication only) and find similar results. Sadly, this is rarely the case!!!

<br>

## Replication and the Reproducibility Spectrum

> _"**Replication** is the ultimate standard by which scientific claims are judged."_ [@Peng2011]

If the results of a study or experiment cannot by replicated by an independent set of investigators then whatever scientific claims were made should be treated with caution! At best, it suggests that evidence for the claim is weak or mixed, or specific to particular ecosystems or other circumstances and cannot be generalized. At worst, there was error (or even dishonesty) in the original study and the claims were plainly false.

Unfortunately, some studies may not be entirely replicable purely due to the nature of the data or phenomenon (e.g. rare phenomena, long term records or very expensive once-off science projects like space missions). In these cases the "gold standard" of full replication (from new data collection to results) cannot be achieved, and we have to settle for a lower rung on the reproducibility spectrum (Figure \@ref(fig:peng)).

**Reproducibility** falls short of full **replication** because the same data are analyzed again, rather than analyzing independently collected data. 

<br>

## The Reproducibility Crisis



<br>

## Why work reproducibly?

Working reproducibly is hugely valuable, because it helps us:
- track down errors in analyses
- build on previous findings and analyses
- compare new analytical approaches to older ones
- repeat the same analyses when new data are collected or added




Barriers to reproducibility:
- Access to data
- Access to the computational workflow
- Access to software
- Access to a comparable computing environment


[More on the reproducibility crisis...]

<br>

```{r peng, echo=FALSE, fig.cap = "The Reproducibility Spectrum [@Peng2011].", fig.width=3, fig.align = 'center'}
knitr::include_graphics("img/peng_reproducibility.jpg")
```

<br>

Working reproducibly is clearly not just a requirement for using quantitative approaches in iterative decision-making, it is central to scientific progress!!!

<br>

## Scientific Workflows

```{r xkcd_data_pipeline, echo=FALSE, fig.cap = "", fig.width=3, fig.align = 'center'}
knitr::include_graphics("img/xkcd_data_pipeline_2x.png")
```

<br>

## Data Management

### Why you need to manage your data

- loss (Michener "data decay curve" fig)
- future self (lose it before ou're finished with it)
- value to yourself for sharing, credit etc (publications and citations), 
- science on general (esp long-term ecology in a time of global change)
- Transparency and accountability

### The Data Life Cycle

```{r datalifecycle, echo=FALSE, fig.cap = "The Data Life Cycle, adapted from https://www.dataone.org/", fig.width=6, fig.align = 'center'}
# load library
library(ggplot2)

# Create test data.
data <- data.frame(
  category=c("1.Plan", "2.Collect", "3.Assure", "4.Describe", "5.Preserve", "6.Discover", "7.Integrate", "8.Analyze"),
  count=rep(12.5, 8)
)
 
# Compute percentages
data$fraction <- data$count / sum(data$count)

# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$category, "\n value: ", data$count)

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
  geom_rect() +
  geom_text(x=3.5, aes(y=labelPosition, label=category, color=category)) + # x here controls label position (inner / outer)
  scale_fill_brewer(palette="Blues") +
  scale_color_brewer(palette="Blues", direction = -1) +
  coord_polar(theta="y") +
  xlim(c(2, 4.5)) +
  theme_void() +
  theme(legend.position = "none")
```


#### Plan (DMPs)

#### Collect

#### Assure

#### Describe

#### Preserve

#### Discover

#### Integrate

#### Analyze

<br>
