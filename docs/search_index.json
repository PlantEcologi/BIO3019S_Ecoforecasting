[["reproducibility.html", "4 Reproducible research 4.1 Replication and the Reproducibility Spectrum 4.2 Why work reproducibly? 4.3 Scientific Workflows 4.4 Data Management", " 4 Reproducible research Before we continue, it’s worth highlighting the similarity between the iterative decision making cycle I’ve outlined in figure ?? and the scientific method, i.e.: Observation &gt; Hypothesis &gt; Experiment &gt; Analyze &gt; Interpret &gt; Report &gt; (Repeat) Figure 4.1: The Scientific Method overlain on iterative decision making. It’s also worth noting that replication is one of the fundamental tenets of science. In other words, published research should be robust enough and the methods described in enough detail that anyone else should be able to repeat the study (using the publication only) and find similar results. Sadly, this is rarely the case!!! 4.1 Replication and the Reproducibility Spectrum “Replication is the ultimate standard by which scientific claims are judged.” (Peng 2011) If the results of a study or experiment cannot by replicated by an independent set of investigators then whatever scientific claims were made should be treated with caution! At best, it suggests that evidence for the claim is weak or mixed, or specific to particular ecosystems or other circumstances and cannot be generalized. At worst, there was error (or even dishonesty) in the original study and the claims were plainly false. Unfortunately, some studies may not be entirely replicable purely due to the nature of the data or phenomenon (e.g. rare phenomena, long term records, loss of species or ecosystems, or very expensive once-off science projects like space missions). In these cases the “gold standard” of full replication (from new data collection to results) cannot be achieved, and we have to settle for a lower rung on the reproducibility spectrum (Figure 4.2). Figure 4.2: The Reproducibility Spectrum (Peng 2011). Reproducibility falls short of full replication because it focuses on reproducing the same result from the same data set, rather than analyzing independently collected data. While this may seem trivial, you’d be surprised at how few studies are even reproducible, let alone replicable. Figure 4.3: ‘Is there a reproducibility* crisis?’ Results from a survey of &gt;1500 top scientists (Baker 2016; Penny 2016). *Note that they did not discern between reproducibility and replicability, and that the terms are often used interchangeably. While full replication is a huge challenge (and sometimes impossible) to achieve, it is something all scientists should be working towards. 4.2 Why work reproducibly? Figure 4.4: Let’s start being more specific about our miracles… Cartoon © Sidney Harris. Used with permission ScienceCartoonsPlus.com Working reproducibly is hugely valuable, because: (Adapted from “Five selfish reasons to work reproducibly” (Markowetz 2015)) It helps us avoid mistakes and/or track down errors in analyses This is what highlighted the importance of working reproducibly for me. In 2017 I published the first evidence of observed climate change impacts on biodiversity in the Fynbos Biome (Slingsby et al. 2017). The analyses were quite complicated, and when working on the revisions I found an error in my R code. Fortunately, it didn’t change the results qualitatively, but it made me realize how easy it is to make a mistake and put the wrong message out there! This encouraged me to make all data and R code from the paper available, so that anyone is free to check my data and analyses and let me (and/or the world) know if they find any errors. It makes it easier to write papers e.g. Dynamic documents like RMarkdown or Jupyter Notebooks update automatically when you change your analyses, so you don’t have to copy/paste or save/insert all tables and figures (or worry about whether you included the latest versions. It helps the review process Often issues picked at by reviewers are matters of clarity/confusion. Sharing your data and analyses allows them to see exactly what you did, not just what you said you did, allowing them to identify the problem and make constructive suggestions. It’s also handy to be able to respond to a reviewer’s comment with something like “That’s a great suggestion, but not really in line with the objectives of the study. We have chosen not to include the suggested analysis, but do provide all data and code so that interested readers can explore this for themselves.” (Feel free to copy and paste - CCO 1.0) It enables continuity of the research When people leave a project (e.g. students/postdocs), or you forget what you did X days/weeks/months/years ago, it can be a serious setback for a project and make it difficult for you or a new student to pick up where things left off. If the data and workflow are well curated and documented this problem is avoided. Trust me, this is a very common problem!!! I have many papers that I (or my students) never published and may never go back to, because I know it’ll take me a few days or weeks to understand the datasets and analyses again… This is obviously incredibly important for long-term projects!!! It helps to build your reputation Working reproducibly makes it clear you’re an honest, open and careful researcher, and should errors be found in your work you’re unlikely to be accused of dishonesty (e.g. see my paper example under point 1 - although no one has told me of any errors yet…). When others reuse your data, code, etc you’re likely to get credit for it (depending on the licensing conditions you specify - see “Preserve” in the Data Life Cycle) And some less selfish reasons (and relevant for ecoforecasting): It allows you (or others) to rapidly build on previous findings and analyses It allows easy comparison of new analytical approaches to older ones It makes it easy to repeat the same analyses when new data are collected or added Reproducibility helps to avoid mistakes. Reproducibility makes it easier to write papers. Reproducibility helps reviewers see it your way. Reproducibility enables continuity of your work. Reproducibility helps to build your reputation. What are the barriers to reproducibility? Access to data Access to the computational workflow Access to software Access to a comparable computing environment Working reproducibly is clearly not just a requirement for using quantitative approaches in iterative decision-making, it is central to scientific progress!!! 4.3 Scientific Workflows Figure 4.5: ‘Data Pipeline’ from https://xkcd.com/2054, used under a CC-BY-NC 2.5 license 4.4 Data Management 4.4.1 Why you need to manage your data loss (Michener “data decay curve” fig) future self (lose it before ou’re finished with it) value to yourself for sharing, credit etc (publications and citations), science on general (esp long-term ecology in a time of global change) Transparency and accountability 4.4.2 The Data Life Cycle Figure 4.6: The Data Life Cycle, adapted from https://www.dataone.org/ 4.4.2.1 Plan (DMPs) 4.4.2.2 Collect 4.4.2.3 Assure 4.4.2.4 Describe 4.4.2.5 Preserve 4.4.2.6 Discover 4.4.2.7 Integrate 4.4.2.8 Analyze References "]]
