[["index.html", "A Minimal Introduction to Reproducible Research and Ecological Forecasting 1 Overview 1.1 General 1.2 Module and Project details 1.3 Acknowledgements and further reading:", " A Minimal Introduction to Reproducible Research and Ecological Forecasting Jasper Slingsby 2021-08-30 1 Overview This module is a minimal introduction to Reproducible Research and Ecological Forecasting for the 3rd year undergraduate Biological Sciences BIO3019S class at the University of Cape Town. 1.1 General I provide a very brief introduction to Ecological Forecasting and the various principles and tools required to make research more reproducible and (hopefully) more useful. We only have a two weeks, so this really is a minimalist introduction. I’ll focus on providing a broad overview of the general framework and motivation, but won’t have time to delve into the more gory theoretical and statistical details. The core outcomes/concepts I hope you’ll come away with: To be able to situate the role of models in science and ecological decision making Familiarity with the concepts and understand the need for Open, Reproducible Science Familiarity with The Data Life Cycle Familiarity with Open Science tools 1.2 Module and Project details Lectures Lectures will be held live, but online 12:00 - 12:45 from the 30th September to the 13th October. The zoom link (see Vula) should stay the same for all lecture sessions. Practicals There is only one practical for this module, 2-5PM on Tuesday the 5th October. Details to follow. 1.3 Acknowledgements and further reading: Many of the following resources were instrumental in me pulling this material together and are worth spending time exploring ecoforecast.org Dietze, Michael C. 2017. Ecological Forecasting. Princeton University Press. https://doi.org/10.2307/j.ctvc7796h. Dietze, Michael C. et al. 2018. “Iterative near-Term Ecological Forecasting: Needs, Opportunities, and Challenges.” Proceedings of the National Academy of Sciences of the United States of America 115 (7): 1424–32. https://doi.org/10.1073/pnas.1710231115. All code, images, etc can be found here. I have only used images etc that were made available online under a non-restrictive license (Creative Commons, etc) and have attributed my sources. Content without attribution is my own and shared under the license below. If there is any content you find concerning with regard to licensing, or that you find offensive, please contact me. Any feedback, positive or negative, is welcome! This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License. "],["how-do-we-make-decisions.html", "2 How do we make decisions?", " 2 How do we make decisions? What factors do you consider when making a decision? "],["intro.html", "3 Models and decision making 3.1 The basics of making a decision 3.2 Getting quantitative 3.3 Iterative decision-making 3.4 Delete from here once done… - How to reference", " 3 Models and decision making 3.1 The basics of making a decision Informing decisions typically requires knowing (or guessing at) something about the future. To this end, once a problem and the need to make a decision have been identified, the factors we consider when making that decision usually include: Evidence Experience Expectation Uncertainty The relationship between these can be represented like so: Figure 3.1: The factors considered when making a decision. Your decision is typically based on your expectation of the outcome. This expectation is based on existing evidence and/or previous experience. Uncertainty is a part of each step. There are a number of reasons why the existing evidence or previous experience may be imperfect for the decision at hand, leading to uncertainty in the expectations. There may also be uncertainty in the way in which you use the evidence and experience to develop your expectation. We will come back to these sources of uncertainty later in the module, but needless to say, quantifying and understanding the uncertainty is crucial in any decision, because if uncertainty is high your expectation may be no better than random, and thus useless for informing your decision. 3.2 Getting quantitative The nice thing about the framework above is that it is similar whether you are approaching the decision qualitatively or quantitatively (i.e. using models and data to inform your decision). Figure 3.2: Using models and data when making a decision. Following a quantitative approach the “evidence” is typically empirical data, which can be fed into a model to make forecasts that can help inform the decision. The “experience” are the current state of knowledge and your prior belief, which you use to specify the type and structure of your model (or ensemble of models) and the scenario(s) you want to evaluate. The “experience” can also help you evaluate the assumptions of your model(s), and if you are using a Bayesian model, can be included directly in the model when specifying priors (more on this later in the module). 3.3 Iterative decision-making Few decisions in natural resource management are once-off, and most are made repeatedly at some time-step (e.g. daily, monthly, seasonally, annually, decadally, etc). Should you burn, cull, harvest, restore, etc? While one should always evaluate the outcome of your decision, this is especially important when the decision will need to be repeated. Figure 3.3: Iterative decision making. When using quantitative forecasts this can be done by collecting and adding new data, and by updating your prior knowledge by evaluating the outcomes of the decision against the original model forecasts. This can tell you whether your forecast was any good and whether you need to refine or replace your model, consider additional scenarios or inputs, etc. Implementing this process quantitatively requires careful management of the data and workflow and would greatly benefit from automation (i.e. it needs to be reproducible and repeatable). 3.4 Delete from here once done… - How to reference You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 3. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter 5. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 3.4: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 3.4. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 3.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 3.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2021) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],["reproducible-research.html", "4 Reproducible research 4.1 The Reproducibility Crisis 4.2 The Data Life Cycle 4.3 Scientific Workflows", " 4 Reproducible research 4.1 The Reproducibility Crisis Before we continue, it’s worth highlighting the similarity between the iterative decision making cycle I’ve outlined in figure 3.3 and the scientific method, i.e.: Observation &gt; Hypothesis &gt; Experiment &gt; Analyze &gt; Interpret &gt; Report &gt; (Repeat) Figure 4.1: The Scientific Method overlain on iterative decision making. It’s also worth noting that reproducibility is one of the fundamental tenets of science. In other words, published research should be robust enough and the methods described in enough detail that anyone else should be able to repeat the study (using the publication only) and find similar results. Sadly, this is rarely the case!!! [More on the reproducibility crisis…] [Working reproducibly and Peng et al. 2011 figure.] Working reproducibly is clearly not just a requirement for using quantitative approaches in iterative decision-making, it is central to scientific progress!!! 4.2 The Data Life Cycle 4.2.1 Why you need to manage your data loss (Michener “data decay curve” fig) future self (lose it before ou’re finished with it) value to yourself for sharing, credit etc (publications and citations), science on general (esp long-term ecology in a time of global change) Transparency and accountability 4.2.2 The steps involved in data management 4.2.2.1 Plan (DMPs) 4.2.2.2 Create 4.2.2.3 Process 4.2.2.4 Document and use 4.2.2.5 Share and preserve 4.2.2.6 Reuse 4.3 Scientific Workflows "],["methods.html", "5 Methods 5.1 math example", " 5 Methods We describe our methods in this chapter. Math can be added in body using usual syntax like this 5.1 math example \\(p\\) is unknown but expected to be around 1/3. Standard error will be approximated \\[ SE = \\sqrt(\\frac{p(1-p)}{n}) \\approx \\sqrt{\\frac{1/3 (1 - 1/3)} {300}} = 0.027 \\] You can also use math in footnotes like this1. We will approximate standard error to 0.0272 where we mention \\(p = \\frac{a}{b}\\)↩︎ \\(p\\) is unknown but expected to be around 1/3. Standard error will be approximated \\[ SE = \\sqrt(\\frac{p(1-p)}{n}) \\approx \\sqrt{\\frac{1/3 (1 - 1/3)} {300}} = 0.027 \\]↩︎ "],["applications.html", "6 Applications 6.1 Example one 6.2 Example two", " 6 Applications Some significant applications are demonstrated in this chapter. 6.1 Example one 6.2 Example two "],["final-words.html", "7 Final Words", " 7 Final Words We have finished a nice book. "],["references.html", "References", " References "]]
