[["index.html", "A Minimal Introduction to Ecological Forecasting and Reproducible Research 1 Overview 1.1 General 1.2 Lectures and practicals 1.3 Preparation 1.4 A bit about me 1.5 Acknowledgements and further reading:", " A Minimal Introduction to Ecological Forecasting and Reproducible Research Jasper Slingsby 2021-10-01 1 Overview This module is a minimal introduction to Ecological Forecasting and Reproducible Research for the 3rd year undergraduate Biological Sciences BIO3019S class at the University of Cape Town. 1.1 General I provide a very brief introduction to the framework for Ecological Forecasting. We only have a two weeks, so this really is a minimalist introduction. I’ll focus on providing a broad overview of the general framework and motivation for ecological forecasting, but won’t have time to delve into the more gory theoretical and statistical details. I mostly use Ecological Forecasting as a framework to highlight various themes and principles that are increasingly important for quantitative biologists - understanding how we inform or make decisions; managing data; working reproducibly; propagating, understanding and reducing uncertainty, etc. Not all of this is fun and exciting, but as I said, it is important stuff for quantitative biologists to know. I’ll try my best to make it interesting! Hopefully by the end of the module you’ll see the value in it all - both for you as an individual and for science and society in general. The core outcomes/concepts I hope you’ll come away with: To be able to situate the role of models and the importance of forecasting in science and ecological decision making Familiarity with the concepts and understand the need for Open, Reproducible Science Familiarity with The Data Life Cycle Familiarity with the value and flexibility of Bayesian statistical methods Some familiarity with sources of uncertainty and the need to characterize, propagate, analyze, reduce and present uncertainties when forecasting 1.2 Lectures and practicals Lectures Lectures will be held live, but online 12:00 - 12:45 from the 30th September to the 13th October. The Zoom link (see Vula) should stay the same for all lecture sessions. I’ll be adding to (and mostly teaching from) these online course notes as we go along. Practicals There is only one practical for this module, 2-5PM on Tuesday the 5th October. There is a separate Zoom link (see Vula). Your report on th practical will be due on Friday, 8 October, 11AM - You will be evaluated on how well you completed the Github task during the prac and your answers to a short set of questions about the analyses. Answering the questions shouldn’t take more than half an hour. Note that we will be covering most of the questions in the lecture on Friday, so if you haven’t submitted your report by 11AM on Friday you will get zero for those questions! 1.3 Preparation For the lecture content: The following 4 minute video will give yo a glossy overview of what most of this module is about You are expected to read Dietze et al. (2018) for Monday the 4th October. You can download it here. For the practical: You need to install and set up RStudio and Github and test your setup. You can find the 11-step instructions in section 2. This may be a bit tedious, but there’s no other option really. I’ve done my best to make it as painless as possible. It should take you about an hour if all goes well… (less if you have R and RStudio installed already). PLEASE DO THE SETUP THIS WEEK!!! I will check in on Monday to see if people are having issues, but don’t expect my help if you haven’t tried by yourself first. Trust me, I will be able to tell… 1.4 A bit about me I’m an ecologist who has become more quantitative through time, but has little formal training in quantitative methods (i.e. I’ve learnt by doing over the past 20 years). As such, I still make elementary mistakes. In fact, the entry requirements for this course are beyond my formal training, so you may have much to teach me! If you spot any errors, confusion or contradictions, please let me know and I’ll get back to you and/or update the course notes accordingly. Hopefully by the end of the course you can suggest changes directly using pull requests to the GitHub repository for the course notes. 1.5 Acknowledgements and further reading: The following resources were instrumental in me pulling this material together and are worth spending time exploring. I cite my sources throughout the course notes, so check out the references at the end of each section and the end of the course notes for more. ecoforecast.org Dietze, Michael C. 2017. Ecological Forecasting. Princeton University Press. https://doi.org/10.2307/j.ctvc7796h. Dietze, Michael C. et al. 2018. “Iterative near-Term Ecological Forecasting: Needs, Opportunities, and Challenges.” Proceedings of the National Academy of Sciences of the United States of America 115 (7): 1424–32. https://doi.org/10.1073/pnas.1710231115. All code, images, etc can be found here. I have only used images and other materials that were made available online under a non-restrictive license (Creative Commons, etc) or for which I have express permission, and have attributed my sources. Content without attribution is my own and shared under the license below. If there are any errors or any content you find concerning with regard to licensing, or that you find offensive, please contact me. Any feedback, positive or negative, is welcome! This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License. References "],["pracprep.html", "2 Preparation for the practical", " 2 Preparation for the practical For the practical, we’ll be using the R statistical programming language and the Git version control system. We’ll also be using an integrated development environment (IDE) for each: RStudio and GitHub, respectively. The installation and setup can be a bit long-winded, but once done you should be good to go until you change or reformat your computer. The steps below are my summary and (hopefully) more intuitive adaptation of the instructions provided for setting up GitHub and version control with R. If my steps don’t work its probably best to read up there. First we’ll start with the necessary software. Download and install the latest version of R Download and install the latest free version of RStudio Desktop Download and install the latest version of Git - accept all the defaults Then get started with GitHub: Create a GitHub account Run through the 10 minute GitHub tutorial that is offered when you activate your GitHub Account (It’ll really help you get the idea behind what Git does!) Now you have RStudio, R and Git installed, and you have a working GitHub account that lets you do stuff online, but what remains is to get GitHub working locally and configuring RStudio to use GitHub. Install GitHub CLI (Command Line Interface). For Windows you can download the installer here Open RStudio. Select the Terminal tab (top left, next to Console) Enter gh auth login, then follow the prompts: Select GitHub.com When prompted for your preferred protocol for Git operations, select HTTPS When asked if you would like to authenticate to Git with your GitHub credentials, enter Y When asked how you would like to authenticate select Login with web browser Copy the 8-digit code and hit Enter Github.com will open in your internet browser - paste the code and hit enter If any of these steps don’t work, just start again with gh auth login in Terminal In RStudio Go to Global Options (from the Tools menu) Click Git/SVN Make sure Enable version control interface for RStudio projects is on If necessary, enter the path for your Git or SVN executable where provided (this shouldn’t be needed, but may) Click Apply Restart RStudio Ok, now everything should be working. The next steps (explained below) are to fork and clone your first repo to see if everything is working, and then to modify a file in RStudio, push it back to your forked repo, and then create a pull request for me to review and accept your changes. This let’s me know that you’ve made it through the preparation for the practical, and it gives me your GitHub username. In GitHub: Make sure you are logged in, search and navigate to JasperUCT/pullltest (spot the 3 “l”s!) Click Fork, which will make a copy of the repository to your own workspace Copy the URL to your own version and follow the instructions below for cloning the repository in RStudio In RStudio: In the top-right of the window you’ll see Project: (None) - click on it and select New Project then Version Control then Git In the Repository URl: box paste the URL to your forked repo (It should look something like : https://github.com/YourGitHubUsername/your-forked-repo_name.git Project directory name should fill automatically For Create project as subdirectory of: hit Browse and navigate through your file system to where you want to put your folder for storing your Git repositories. I recommend something like ~Documents/GIT (If you’ve used Git before you may have set this already and can skip this step) Click Create Repository Your RStudio window should now look like this: Figure 2.1: What you should see… Note there are three files in the Files tab in the bottom-right window, and you should see a Git tab for the top-right window. It also says pullltest in the project drop-down top-right on mine, but yours will display the name you gave your forked repo. Open the README.md file in RStudio Add your message (something like “Hi! This is Real Name and I’ve made it this far!!!”) and save the file Select the Git tab in the top-right window Check the box next to README.md and click Commit Add a Commit message to say what changes you’ve made Then hit Push It will ask you to authenticate. Select Authenticate in your web browser. The web browser will ask you to give Git permissions. Allow the permissions and it should work. If you get an error at this point to the effect of “You do not have permission to push to this repository,” then you may have forgotten to fork your own repo from my one and are trying to push to mine… If so, start again from step 9. Final step!!! In GitHub (i.e. online) Click Pull requests (top-leftish) Click New pull request (green, top-right) Click Create pull request (green, top-right) It should already be on this repo unless you’ve been doing other things in Git In the comment window put your name so I know who you are if it isn’t obvious from your GitHub username Click Create pull request (green, bottom-right) And you’re done!!! I’ll get a notification of your pull request and, if all’s in order, I’ll accept it. If not, I’ll reply with a comment on the pull request. You should receive a notification via the email you registered with your GitHub account. "],["models.html", "3 Models and decision making 3.1 The basics of making a decision 3.2 Getting quantitative 3.3 Iterative decision-making 3.4 Iterative decision-making and the scientific method 3.5 The importance of prediction in ecology 3.6 Iterative near-term ecological forecasting 3.7 Iterative ecological forecasting in context 3.8 Reproducible research", " 3 Models and decision making What factors do you consider when making a decision? 3.1 The basics of making a decision Informing decisions typically requires knowing (or guessing at) something about the future. To this end, once a problem and the need to make a decision have been identified, the factors we consider when making that decision usually include: Evidence Experience Expectation Uncertainty The relationship between these can be represented like so: Figure 3.1: The factors considered when making a decision. Your decision is typically based on your expectation of the outcome. This expectation is based on existing evidence and/or previous experience. Uncertainty is a part of each step. There are a number of reasons why the existing evidence or previous experience may be imperfect for the decision at hand, leading to uncertainty in the expectations. There may also be uncertainty in the way in which you use the evidence and experience to develop your expectation. We’ll come back to these sources of uncertainty later in the module, but needless to say, quantifying and understanding the uncertainty is crucial in any decision. If uncertainty is high your expectation may be no better than random, and thus useless for informing your decision. Quantifying uncertainty properly helps us circumvent two evils which could mislead decision makers: being falsely overconfident in our predictions (potentially leading to a “wrong” decision), or being falsely uncertain in our predictions (which would encourage overly conservative decisions/actions which may be wasteful or less effective). Lastly, ignoring or quantifying uncertainty incorrectly can lead to bias predictions. 3.2 Getting quantitative The nice thing about the framework above is that it is similar whether you are approaching the decision qualitatively or quantitatively (i.e. using models and data to inform your decision). Figure 3.2: Using models and data when making a decision. Following a quantitative approach the “evidence” is typically empirical data, which can be fed into a model to make forecasts that can help inform the decision. The “experience” are the current state of knowledge and your prior belief, which you use to specify the type and structure of your model (or ensemble of models) and the scenario(s) you want to evaluate. The “experience” can also help you evaluate the assumptions of your model(s), and, if you are using a Bayesian model, can be included directly in the model when specifying your prior beliefs (more on this later in the module). Figure 3.3: A hypothetical example where a model can help you make a decision. The data (points) are the evidence, while the experience or current state of knowledge are used to specify the model (a linear model in this case). Here the relationship between effort invested and reward is nearly 1 to 1, suggesting to the decision-maker that the more effort you invest, the more reward you will reap. That said, there is scatter around in the points around the 1:1 line, suggesting some uncertainty. 3.3 Iterative decision-making Few decisions in natural resource management are once-off, and most are made repeatedly at some time-step (e.g. daily, monthly, seasonally, annually, decadally, etc). Should you burn, cull, harvest, restore, etc? While one should always evaluate the outcome of your decision, this does not always happen… Evaluating the outcome is especially important when the decision will need to be repeated, so that you can learn from experience. Figure 3.4: Iterative decision making. When using quantitative forecasts this can be done by collecting new data and updating your prior knowledge by evaluating the outcomes of the decision against the original model forecasts. This can tell you whether your forecast was any good and whether you need to refine or replace your model, consider additional scenarios or inputs, etc. We’ll discuss doing this quantitatively in section ??, by fusing your new data and knowledge into a new forecast. Figure 3.5: Revisiting our Effort to Reward example, what would you do if the decision-maker decided to invest huge effort, but the next few data points looked like this? 3.4 Iterative decision-making and the scientific method It’s worth highlighting the similarity between the iterative decision making cycle I’ve outlined in Figure 3.4 and the scientific method, i.e.: Observation &gt; Hypothesis &gt; Experiment &gt; Analyze &gt; Interpret &gt; Report &gt; (Repeat) Figure 3.6: The Scientific Method overlain on iterative decision making. So a focus on iterative decision-making facilitates iterative learning (i.e. scientific progress). 3.5 The importance of prediction in ecology “prediction is the only way to demonstrate scientific understanding” (Houlahan et al. 2017) While this view may be slightly overstated, it is a very good point. If we cannot make reasonably good predictions, we’re missing something. Unfortunately, prediction has not been a central focus in ecology, impeding progress in the improvement of our ecological understanding. In ecology we mostly test qualitative, imprecise hypotheses: “Does X have an effect on Y?” rather than “What is the relationship between X and Y?” or better yet “What value would we expect Y to be, given a particular value of X?”. Without testing precise hypotheses and using the results to make testable predictions we don’t know if our findings are generalizable beyond the specific data set we collected. If our results are not generalizable, then we’re not really making progress towards a better understanding of ecology. Figure 3.7: Prediction… from xkcd.com/2370, used under a CC-BY-NC 2.5 license. To make predictions we need models, and models provide structured summaries of our current ecological understanding (conceptual or quantitative, but preferably quantitative, because these are easier to compare). Without making predictions and comparing the skill of new models to old ones, we can’t track if we are making progress! A key point here is that the predictions must be testable! We do use a lot of models in ecology, and even use them to make predictions (e.g. species distribution models (SDMs), dynamic vegetation models (DVMs), etc), but these predictions are typically 50+ years into the future, which is way to long to wait to see if our predictions were reasonable or useful. A quick aside on model validation vs testing predictions: Testing predictions with new data collected after you’ve made your predictions is the most robust way to validate a model, but you usually want to do some form of validation before you make your final predictions to make sure the model is working reasonably well. For this we most commonly do some form of cross-validation, whereby we split the data into a “training” subset (that we use for fitting (or training) the model) and a “test” subset (that we try to predict). If your model is no good at predicting your test data, there’s probably no point in making predictions into the future… 3.6 Iterative near-term ecological forecasting The recent growth in interest in iterative ecological forecasting seeks to not only make prediction a central focus in ecology, but to do so on a time scale that is both useful for decision makers and allows us to learn from testing our predictions (days to decades). The “gold standard” here is an informatics pipeline that can ingest new data and make new forecasts automatically with minimal user input. This is a great initiative, but as we will see it poses a number of major challenges and requires a big improvement in quantitative skills in biology (hence this course…). Fortunately, as we will see during the module, any steps towards the gold standard is likely to be useful, even if you never get there. Here I break down the individual components of ecological forecasting (using figures from a lecture on data assimilation by Michael Dietze): You start with your initial conditions (data and knowledge that feeds into designing and fitting your model) You make forecasts (i.e. predictions into the future) using your model, based on your initial conditions. You monitor and collect new observations to compare with your forecasts and original observations (i.e. initial conditions). Finally, you analyze the new observations in the context of your forecasts and original observations, and update the initial conditions for the next iteration of the forecast. Figure 3.8: The iterative ecological forecasting cycle in the context of the scientific method, demonstrating how we stand to learn from making iterative forecasts. From lecture on data assimilation by Michael Dietze. (Please excuse that the colours of the distributions have changed from above…). The key steps are: Make a forecast based on your current data and understanding Collect new observations and compare them to your forecast Analyze the new observations in the context of your forecast and original data Update estimates of the current state of the system (data and understanding), before making a new forecast Two things not indicated in this diagram are: that when making the forecast and analyzing the new observations you can learn about the various sources and drivers of uncertainty in your forecast and use that to adapt or guide what and how to monitor so that you can reduce those uncertainties developing this into an automated informatics pipeline is best dine in a reproducible research framework Iterative ecological forecasts are thus aimed at: applied outcomes, through providing evidence to support decision making knowledge generation through iterative learning i.e. the scientific method So it’s a great way of getting scientists to engage in real-world problems, demonstrating the value of our science, and learning by doing! 3.7 Iterative ecological forecasting in context The figure below from Dietze et al. (2018) provides an expanded representation of these conceptual links between iterative ecological forecasting, the scientific method, and decision making (here in the context of adaptive management, which is a management paradigm that focuses on learning by doing). Figure 3.9: Conceptual relationships between iterative ecological forecasting, adaptive decision-making, adaptive monitoring, and the scientific method cycles (Dietze et al. 2018). The iterative ecological forecasting cycle is tightly aligned to the scientific method cycle: Hypotheses (A) are embedded in models (B). The models integrate over uncertainties in initial conditions (IC), inputs, and parameters to make probabilistic forecasts (the purple distributions, Fx, in step C), sometimes for multiple alternative scenarios. New observations are then compared with these predictions (D) to update estimates of the current state of the system (Analysis) and assess model performance (E), allowing for the selection among alternative model hypotheses (Test and Refine). The iterative forecasting cycle also feeds into adaptive management and monitoring: In Adaptive Management and decision analysis, alternative decision scenarios are generated (2) based on an assessment of a problem (1). These decision scenarios are typically used to define the scenarios (or boundary conditions) for which models are run (“Scenarios” arrow), but can also feed into scientific hypotheses (not shown). Forecasts (Fx) are key in assessing the trade-offs and relative merits between alternative decision options (3). The decision(s) taken (4) determine the monitoring requirements (5), which allow us to evaluate the outcomes and reassess the problem (1), and start the adaptive management cycle again. Note that the iterative forecast cycle is also useful for adaptive management in that the analysis and partitioning of forecast uncertainties (from step C) can provide further guidance on what and how to monitor, so as to optimize the reduction in model uncertainties. This represents Adaptive Monitoring (dashed line) and is a cycle of itself (Lindenmayer and Likens 2009), but is largely subsumed by the other cycles here so we won’t go into it any further here. Thus the iterative cycles of science, forecasting, management and monitoring are tightly intertwined and can interact continuously. 3.8 Reproducible research What isn’t clear from Figure 3.9 is that all of this needs to be founded on a highly efficient informatics pipeline that is robust and rapidly updateable. Since the emphasis here is on near-term forecasts to inform management, if the process of adding new data and updating the forecasts is too slow, the value of the forecasts is lost. As we’ll see in future lectures, the best way to build a highly efficient informatics pipeline is to follow reproducible research principles (section ??), including good (and rapid) data management (section ??). Adding this link to Figure 3.9 helps to highlight what I like to think of as “The Olympian Challenge of data-driven ecological decision making”. Figure 3.10: The Olympian Challenge of data-driven ecological decision making. Working reproducibly requires learning a lot of skills and can take a lot of effort, but is well worth it beyond it’s utility for ecological forecasting - for you as an individual, and for science in general. This is why I decided to make it part of the title for the module and the focus of at least two lectures and the practical. References "],["forecasts.html", "4 Making forecasts 4.1 Proteaceae as a model organisms 4.2 Proteaceae as management indicators 4.3 Potential issues with the rules of thumb… 4.4 Assessing population viability 4.5 Climate and fire-driven changes in demographic rates and distribution 4.6 Near-term iterative ecological forecasts?", " 4 Making forecasts You’re probably wondering “What are ecological forecasts?” or “Where are we going with all this?” The focus of this section is to provide some context with an example of what I believe is one forecasting need and opportunity in the Fynbos Biome. I was going to give 3 examples, but rapidly realized it would be too long a lecture. I’ll be using the other examples to illustrate various principles in later lectures, but hopefully this example will provide some practical context for some of the issues we’ll address in the rest of the module. Note: This example has not yet been developed into full near-term iterative ecological forecasts sensu Dietze et al (2018). I also don’t think they necessarily have to get all the way there to be useful. Think of it as an “ecological forecasting spectrum” where the gold standard is fully developed and automated near-term iterative ecological forecasts. Figure 4.1: Conceptual relationships between iterative ecological forecasting, adaptive decision-making, adaptive monitoring, and the scientific method cycles (Dietze et al. 2018). I’ll start with a reminder that the goal here is to focus the forecasting effort on an applied real-world problem and to do so in a manner that allows us to learn and improve our scientific understanding of the system. 4.1 Proteaceae as a model organisms The Proteaceae are probably the best studied and understood plant family in the Fynbos Biome. They have been the focus of a number of large, focused research programmes and are used as indicator species for various conservation management applications. There has been extensive locality and demographic data have been collected by conservation authorities (CapeNature and SANParks), citizen scientists (Protea Atlas Project and iNaturalist) and researchers since the late 1970s and before, and this is reflected in the large (and growing) scientific literature on the family. Figure 4.2: Temporal dynamics of publications on South African Proteaceae based on a Web of Science search on 13 June 2012. Figure from Schurr et al. (2012). A huge benefit of the herculean Proteaceae data collection (and management) effort is that it provides all the data we need to parameterize various types of models. In fact, data on the Proteaceae have been hugely important for the global development of species distribution and demographic models (see Schurr et al. (2012), but also many subsequent papers). Because they are the best-studied group of plants in the Fynbos, they are heavily-utilized for informing conservation planning, management and monitoring. Some examples include informing: protected area planning wildfire management wildflower harvesting climate change monitoring I’m sure there are others I’ve forgotten… 4.2 Proteaceae as management indicators Our knowledge of the demography of the Proteaceae is used for the direct management of Fynbos in two ways: Firstly, at the species level, for setting guidelines for sustainable wild harvesting of their inflorescences Secondly, at the ecosystem level, to help determine acceptable fire return intervals A quick refresher on Proteaceae life cycles and demography: Figure 4.3: Protea cynaroides on Table Mountain showing current inflorescences and older (grey), closed cones that protect seeds from fire and release them into the post-fire environment. Figure 4.4: The fire-driven life-cycle of Fynbos Proteaceae species, including harvesting, taken from (Treurnicht et al. 2021). Population size/stability are determined by key demographic rates of adult fecundity (size of the canopy seed bank), post-fire seedling recruitment and adult fire survival (blue–grey boxes). These rates are affected in various ways by environmental conditions, density dependence, the timing, intensity and severity of fire, wildflower harvesting, etc The management guidelines are currently set by “rule of thumb”1: Wildflower harvesting: “[There should be no] harvesting until at least 50% of the population had commenced flowering, a harvest of up to 50% of current season flower heads after this stage, and no harvesting at least one year prior to a prescribed burn” (Wilgen et al. 2016) Fire return intervals: “No fire should be permitted in fynbos until at least 50% of the population of the slowest-maturing species in an area have flowered for at least three successive seasons (or at least 90% of the individuals of the slowest maturing species in the area have flowered and produced seed). Similarly, a fire is probably not necessary unless a third or more of the plants of these slow-maturing species are senescent (i.e. dying or no longer producing flowers and seed).” (CapeNature, n.d.) Both these rules are based on the premise that maintaining seed banks is the key to the persistence of Proteaceae populations. i.e. that there is a large enough seed bank present when a fire occurs for the population to recover. But is focusing on seeds alone reasonable? And if so, do the thresholds in the guidelines allow for enough seed? 4.3 Potential issues with the rules of thumb… Figure 4.5 presents extensive field data for 26 Proteaceae species from Treurnicht et al. (2016). What issues might these data suggest for the rules of thumb? Figure 4.5: Variation in demographic rates of 26 serotinous Proteaceae species of seeder and sprouter life-history types across their distribution range (Treurnicht et al. 2016). (a) Adult fire survival; (b) Individual fecundity (F); and (c) Per-capita recruitment rate (R). These issues include: species differ in their reliance on seed for their survival (e.g. sprouters vs seeders) sprouters have high persistence of adults through fires and need fewer new recruits from seed seeder adults are killed by fire, so populations depend entirely on recruitment from seed species vary in their fecundity (total number of seeds) fecundity = number of inflorescences produced multiplied by the number of seeds per inflorescence species vary in seed viability and recruitment success viability depends on pathogens, seed predators and other factors - many linked to the age of the seed or inflorescence seed-specific recruitment depends on viability and seed properties (size etc), conditions during the establishment phase (rainfall etc), finding suitable microsites, etc. per-capita recruitment is the combination of fecundity and seed-specific recruitment Figure 4.6 present variation within one species that suggests more issues… Figure 4.6: Intraspecific variation in (a) fecundity and (b) recruitment in response to range-wide variation in fire return interval (time since fire), adult population density and soil moisture stress (% days with soil moisture stress) for Protea punctata (Treurnicht et al. 2016). there is also intraspecific variation in fecundity and recruitment along climatic, soil, fire regime, population density, pollinator availability and other gradients and there is interspecific variation in this intraspecific variation i.e. species vary among populations in their response to climatic, soil, pollinator availability and other gradients 4.4 Assessing population viability Fortunately, we can address these issues by using the data in demographic models to perform population viability analysis under varying harvesting rates (e.g. Treurnicht et al. 2021). Figure 4.7: Sensitivity to wildflower harvesting for various Proteaceae species (Treurnicht et al. 2021). Above: Intraspecific variation in sensitivity to harvesting depicted as maps for four different species with pink dots highlighting where the change in population-level extinction probability (the difference between extinction probabilities under 0% and 50% harvesting) is greater than 0.1. The white and black areas depict species-specific occurrence records and the geographical distribution of all Proteaceae in the Cape Floristic Region, respectively. Below: Interspecific variation in sensitivity to harvesting depicted as the proportion of populations per species that are highly vulnerable to harvesting. These models suggest that following the current harvesting guidelines can greatly increase the probability of many populations going extinct (Figure 4.7; Treurnicht et al. (2021)), and that they would threaten a large portion of populations for some species, including the most commercially valuable ones! But is that enough? So what should the harvesting guidelines be? Are we sure they would be effective and what if there are “ecological surprises” that make them inappropriate? For example, Treurnicht et al. (2021) did not consider changing climate or fire regimes? Should we just ban wildflower harvesting altogether to be safe? While it isn’t a huge industry, a ban would be undesirable for a number of reasons: many livelihoods depend on wildflower harvesting, often among the very poor while some species are targeted and may decline as a result, at least it’s still Fynbos. Removing the option to earn from that land would risk forcing the landowner to consider more destructive land use activities or potentially convert it to other land cover types while some species may struggle under the existing guidelines, some species are largely unaffected and can quite happily be harvested What we really need is ongoing monitoring and updated forecasts that respond and adjust the guidelines to allow sustainable harvesting while not threatening the species. Ideally, these forecasts would include the impacts of changing climate and fire. 4.5 Climate and fire-driven changes in demographic rates and distribution Merow et al. (2014) combined demographic modelling and species distribution modelling using a “Demographic Distribution Model” whereby they used spatial covariation between demographic rates and environmental conditions to infer where the species can maintain positive population growth rates under current and future climate and fire conditions. Interesting side note: This analysis used integral projection models (IPMs), which you can think of as the “next generation” of the Leslie matrix model that you will be familiar with. In IPMs the state variable is size (not age) and there are far more classes (i.e. rows and columns in the “matrix”). The (very oversimplified explanation of) the advantage of this is that you can build regression models for the vital rates as a function of plant size and environmental parameters and then relate those back to your transition matrix. This allows you to explore the effect of spatial covariates (climate, soil, fire, etc) on demographic rates, which would be very difficult to do if you only had a few size classes. This also allow you to make projections for different conditions, allowing you to explorethe effetcs of climate change, altered fire regimes, etc. Figure 4.8: Estimated vital rates of Protea repens across the CFR. Figure from Merow et al. (2014). First, they modeled the species’ individual vital rates as a function of environmental variation across its range (Figure 4.8). Then they combined them to estimate the population growth rates \\(\\lambda\\) per pixel, providing an indication of where the population should remain stable or increase (\\(\\lambda&gt;1\\)) or decline and go extinct (\\(\\lambda&lt;1\\)). This was used as a threshold to map the species’ distribution (Figure 4.9). Figure 4.9: Model evaluation of the predicted population growth rate (\\(\\lambda\\)) and distribution of Protea repens across the CFR. (a) Mean \\(\\lambda\\) and (b) interquartile range of \\(\\lambda\\). (c–d) Evaluation of (a) using presence/absence data. (e) Posterior probability that \\(\\lambda\\) &gt; 1, representing a viable population. (f) Evaluation of (a) using ordinal abundance data. Figure from Merow et al. (2014). Once they’d done this validation and established that the model worked reasonably well they were able to do projections under altered fire regimes or climate conditions (Figure 4.10). Figure 4.10: Projections of the change in population growth rates of Protea repens under different scenarios. (a–b) Reducing (increasing) the observed fire return time by 4 yr. (c) Variation of mean population growth rate as a function of fire return time. The horizontal dashed line indicates where the growth rate = 1. (d) The difference between present day predictions and projections under future climate change scenario with temperature increased by 1 degree and precipitation reduced by 10%. Figure from Merow et al. (2014). There’s a lot of interesting spatial variation in the species’ expected response to changing conditions! The beauty of this analysis is that it: can tell us where we are most likely to see a negative response - guiding where to monitor can break that response down into its component vital rates - i.e. growth, seed production (fecundity), survival, etc - which are all things that are relatively easy to monitor! can easily include or be used to derive sustainable harvesting rates 4.6 Near-term iterative ecological forecasts? So we have the initial data and models required to be able to monitor and forecast multiple Proteaceae species responses to harvesting, wildfire and changing climatic conditions. While the work by Merow et al. (2014), Treurnicht et al. (2021) and others represent ecological forecasts, they currently aren’t iterative, so we are missing the opportunity to learn and refine the models. This also means that we’re not feeding up-to-date information to planners and decision makers. What do we need to do to develop them into near-term iterative ecological forecasts? Figure 4.11: The iterative ecological forecasting cycle in the context of the scientific method, demonstrating how we stand to learn from making iterative forecasts. From lecture on data assimilation by Michael Dietze. (Please excuse that the colours of the distributions have changed from above…). Firstly, they are either not specific about when they are forecasting to (e.g. Treurnicht et al. (2021) ran their models to estimate extinction probabilities over 100 years in response to different harvesting regimes), or they are too far into the future to be amenable to iterative assessment, learning and updating (e.g. Merow et al. (2014) project to 2050). We need to make the forecasts near-term, such as a range of scenarios 5-10 years into the future, or 1-2 years into the next fire cycle. Secondly, while various parties hold various datasets, we need to coordinate data collection among citizen scientists, conservation authorities, scientists, etc and centralize data management so that it can feed data back into the modelling workflow. Thirdly, we need to adapt the models and workflow to be able to ingest and assimilate new data and produce new forecasts automatically. Lastly, we need to make sure that the models adequately characterize and propagate uncertainty throughout the analyses so that we can focus data collection and model development to reduce the uncertainty in forecasts. Fortunately, the models are built in a Bayesian framework and already do a pretty good job of handling uncertainty. Clearly, while huge effort has been invested into the demography of Proteaceae, and they are likely to be one of the lowest hanging fruit for development into near-term iterative ecological forecasts, there is a lot more work to be done! Still, the history of productive research on Proteaceae shows it would clearly be worth the effort, and we already have decades of data that allow us to learn by backcasting or forecasting from old to more recently collected data. Even if early forecasts are woefully wrong, they will help us learn and improve. Once the informatics pipeline is developed, we could start adding other species - e.g. restios, ericas, animals, etc. This is important because the fire requirements for Proteaceae are not necessarily representative of all Fynbos species… “The need to start forecasting is now; the time for making ecology more predictive is here, and learning by doing is the fastest route to drive the science forward.” - Dietze et al. (2018) References "],["references.html", "References", " References "]]
