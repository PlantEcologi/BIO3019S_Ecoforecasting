---
title: ""
author: ""
format: 
  revealjs:
    theme: dark
    slide-number: true
    self-contained: true
editor: visual
bibliography: book.bib
---

# Reproducible Research {background-color="#33431e"}

Jasper Slingsby

## The Reproducibility Crisis {background-color="#33431e"}

<br>

> *"**Replication** is the ultimate standard by which scientific claims are judged."* - @Peng2011

-   Replication is one of the fundamental tenets of science
-   Findings from studies that cannot be independently replicated should be treated with caution!
    -   Either they are not generalisable (cf. prediction) or worse, there was an error in the study!

## The Reproducibility Crisis {background-color="#33431e"}

Sadly, we have a problem...

!['Is there a reproducibility crisis?' - A survey of \>1500 scientists [@Baker2016; @Penny2016].](img/reprocrisis-1.png)

## Reproducible Research {background-color="#33431e"}

<br>

-   Makes use of modern software tools to share data, code, etc to allow others to reproduce the same result as the original study, thus ***making all analyses open and transparent**.*

    -   This is ***central to scientific progress!!!***

<br>

-   BONUS: working reproducibly ***facilitates automated workflows*** needed for iterative ecological forecasting!

<br>

## Replication vs Reproducibility {background-color="#33431e"}

<br>

-   ***Reproducibility*** falls short of full ***replication*** because it focuses on reproducing the same result ***from the same data set***, rather than analyzing independently collected data.

<br>

-   This difference may seem trivial, but you'd be surprised at how few studies are even reproducible, let alone replicable.

##  {.smaller background-color="#33431e"}

### Replication and the Reproducibility Spectrum

![](img/peng_reproducibility.jpg)

-   Full replication is a huge challenge, and sometimes impossible, e.g.
    -   rare phenomena, long term records, very expensive projects like space missions, etc
-   Where the "gold standard" of full replication cannot be achieved, we have to settle for a lower rung somewhere on ***The Reproducibility Spectrum*** [@Peng2011]

## Why work reproducibly? {.smaller background-color="#33431e"}

![Let's start being more specific about our miracles... Cartoon Â© Sidney Harris. Used with permission [ScienceCartoonsPlus.com](www.ScienceCartoonsPlus.com)](img/miracle.jpg)

## Why work reproducibly? {.smaller background-color="#33431e"}

<br>

> "*Five selfish reasons to work reproducibly*" [@Markowetz2015]

1.  Its ***transparent and open*** - helping avoid mistakes or track down errors
2.  It makes it ***easier to write papers*** - faster tracking of changes and manuscript updates
3.  It ***helps the review process*** - reviewers can actually see (and do!) what you did
4.  It ***enables continuity*** of research - simplifying project handover (esp. past to future you!)
5.  It builds ***reputation*** - showing integrity and gaining credit where your work is reused

## Why work reproducibly? {.smaller background-color="#33431e"}

<br>

Some less selfish reasons (and relevant for ecoforecasting):

6.  It ***speeds scientific progress*** facilitating building on previous findings and analyses

7.  It ***allows easy comparison*** of new analytical approaches to older ones

8.  It makes it easy to ***repeat analyses on new data***, e.g. for ecological forecasting or LTER[^3_reproducibility-1]

9.  The tools are ***useful beyond research***, e.g. making websites, presentations

10. Reproducible research ***skills are highly sought after!***

-   Skills are important should you decide to leave science...
-   Within science, more and more environmental organizations and NGOs are hiring data scientists or scientists with strong data and quantitative skills

[^3_reproducibility-1]: Long Term Ecological Research

## Barriers to working reproducibly {.smaller background-color="#33431e"}

From "A Beginner's Guide to Conducting Reproducible Research" [@Alston2021]:

<br>

**1. Complexity**

-   There's a _learning curve_ in getting to know and use the tools effectively
    -   One is always tempted by the "easy option" of doing it the way you already know or using "user-friendly" proprietary software

**2. Technological change**

-   Hardware and software change over time, making it difficult to rerun old analyses
    -   This should be less of a problem as more tools like contained computing environments become available

## Barriers to working reproducibly {.smaller background-color="#33431e"}

**3. Human error**

-   Simple mistakes or poor documentation can easily make a study irreproducible.
    -   Most reproducible research tools are actually aimed at solving this problem!

**4. Intellectual property rights**

-   Rational self-interest can lead to hesitation to share data and code via many pathways:
    -   Fear of not getting credit; Concern that the materials shared will be used incorrectly or unethically; etc
    -   Hopefully most of these issues will be solved by better awareness of licensing issues, attribution, etc, as the culture of reproducible research grows

## Reproducible Scientific Workflows {.smaller background-color="#33431e"}

!['Data Pipeline' from [xkcd.com/2054](https://xkcd.com/2054), used under a [CC-BY-NC 2.5 license](https://creativecommons.org/licenses/by-nc/2.5/).](img/xkcd_data_pipeline_2x.png)

<br>

Working reproducibly requires careful planning and documentation of each step in your scientific workflow from *planning* your data collection to *sharing* your results.

## Reproducible Scientific Workflows {background-color="#33431e"}

Entail overlapping/intertwined components, namely:

1.  Data management
2.  File and folder management
3.  Coding and code management (data manipulation and analyses)
4.  Computing environment and software
5.  Sharing of the data, metadata, code, publications and any other relevant materials

## 1. Data management {background-color="#33431e"}

<br/>

This is a big topic and has a separate section in my notes. 

<br/>

**_Read the notes_** as this is NB information for you to know, and the content is still be examinable - although I will not expect you to know it in as much detail.

## 1. Data management {.smaller background-color="#33431e"}

Data loss is the norm... Good data management is key!!!

```{r datadecay, echo=FALSE, fig.cap = "The 'Data Decay Curve' [@Michener1997]", fig.width=3, fig.align = 'center', out.width="75%"}
knitr::include_graphics("img/datadecaycurve.jpg")
```


## 1. Data management {.smaller background-color="#33431e"}

```{r datalifecycle, echo=FALSE, fig.cap = "The Data Life Cycle, adapted from https://www.dataone.org/", fig.width=6, fig.align = 'center', out.width="100%"}
# load library
library(ggplot2)

# Create test data.
data <- data.frame(
  category=c("1.Plan", "2.Collect", "3.Assure", "4.Describe", "5.Preserve", "6.Discover", "7.Integrate", "8.Analyze"),
  count=rep(12.5, 8)
)
 
# Compute percentages
data$fraction <- data$count / sum(data$count)

# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$category, "\n value: ", data$count)

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
  geom_rect() +
  geom_text(x=3.5, aes(y=labelPosition, label=category)) + #, color=category)) + # x here controls label position (inner / outer)
  scale_fill_brewer(palette="Blues") +
#  scale_color_brewer(palette="Blues", direction = -1) +
  coord_polar(theta="y") +
  xlim(c(2, 4.5)) +
  theme_void() +
  theme(legend.position = "none")
```

## Plan {.smaller background-color="#c2c190"}

Good data management begins with planning. You essentially **outline the plan for every step of the cycle in as much detail as possible**.

Fortunately, there are **online data management planning tools** that make it easy to develop a **Data Management Plan (DMP)**.

```{r uctdmp, echo=FALSE, fig.cap = "Screenshot of [UCT's Data Management Planning Tool's Data Management Checklist.](http://www.digitalservices.lib.uct.ac.za/dls/systems/uct-dmp)", fig.width=3, fig.align = 'center', out.width="90%"}
knitr::include_graphics("img/UCTDMP.png")
```

**A DMP is a living document and should be regularly revised during the life of a project!**

## Collect & Assure {.smaller background-color="#c2c190"}

I advocate that _**it is foolish to collect data without doing quality assurance and quality control (QA/QC) as you go**_, irrespective of how you are collecting the data.

```{r appsheet, echo=FALSE, fig.cap = "An example data collection app I built in [AppSheet](https://www.appsheet.com) that allows you to log GPS coordinates, take photos, record various fields, etc.", fig.width=3, fig.align = 'center', out.width="90%"}
knitr::include_graphics("img/veldwatch.png")
```

There are many tools that allow you to do quality assurance and quality control as you collect the data (or progressively shortly after data collection events).

## Describe, Preserve, Discover {.smaller background-color="#c2c190"}

::: columns
::: {.column width="55%"}

```{r fairdata, echo=FALSE, fig.cap = "The FAIR data principles [ErrantScience.com](https://errantscience.com/).", fig.width=3, fig.align = 'center', out.width="100%"}
knitr::include_graphics("img/fairdata.jpg")
```

:::
::: {.column width="40%"}
**Global databases:**

- [GenBank](https://www.ncbi.nlm.nih.gov/genbank/) - for molecular data
- [TRY](https://www.try-db.org/TryWeb/Home.php) - for plant traits
- [Dryad](https://datadryad.org) - for general biological and environmental data

**South African databases:**

- [SANBI](https://www.sanbi.org/resources/infobases/) (biodiversity), [SAEON](https://catalogue.saeon.ac.za/) (environmental and biodiversity)

**"Generalist" repositories:**

- [FigShare](https://figshare.com/) (incl. UCT's [ZivaHub](https://zivahub.uct.ac.za/)), [Zenodo](https://zenodo.org/)
:::
::::

## Integrate & Analyse {.smaller background-color="#c2c190"}

"The fun bit", but again, there are many things to bear in mind and keep track of so that your analysis is repeatable. This is largely covered by the sections on _Coding and code management_ and _Computing environment and software_ below

![Artwork \@allison_horst](img/tidydata_5.jpg)

## 2. File and folder management {.smaller background-color="#33431e"}

::: columns
::: {.column width="45%"}
!['Documents' from [xkcd.com/1459](https://xkcd.com/1459), used under a [CC-BY-NC 2.5 license](https://creativecommons.org/licenses/by-nc/2.5/).](img/documentnaming.png)
:::

::: {.column width="55%"}
<br>

Project files and folders can get unwieldy fast and really bog you down!

<br>

The main considerations are:

-   defining a simple, common, intuitive folder structure
-   using informative file names
-   version control where possible
    -   e.g. GitHub, Google Docs, etc
:::
:::

##  {.smaller background-color="#c2c190"}

::: columns
::: {.column width="46%"}
### Folders

Most projects have similar requirements

Here's how I usually manage my folders:

![](img/gitrepofolders.png) <br>

-   "code"contains code for analyses
-   "data" often has separate "raw" and "processed" (or "clean") folders
    -   Large files (e.g. GIS) may be stored elsewhere
-   "output" contains figures and tables
:::

::: {.column width="4%"}
:::

::: {.column width="50%"}
::: fragment
### Names should be

-   machine readable
    -   avoid spaces and funny punctuation
    -   support searching and splitting, e.g. "data_raw.csv", "data_clean.csv" can be searched by keywords and split into fields by "\_"
-   human readable
    -   contents self evident from the name
-   support sorting
    -   numeric or character prefixes separate files by component or step
    -   folder structure helps here too
:::
:::
:::

## 3. Coding and code management {.smaller background-color="#33431e"}

<br>

### Why write code?

"Point-and-click" software like Excel, Statistica, etc may seem easier, but you'll regret it in the long run... e.g. When you have to rerun or remember what you did?

<br>

::: fragment
### Coding rules

Coding is communication. Messy code is bad communication. Bad communication hampers collaboration and makes it easier to make mistakes...
:::

<br>

::: fragment
### Version control

[Streamline, collaborate, reuse, contribute, and fail safely...](https://www.openscapes.org/blog/2022/05/27/github-illustrated-series/)
:::

## Why write code? {.smaller background-color="#c2c190"}

-   **Automation** - reusing code is one click, and you're unlikely to introduce errors
-   A script provides a **record of your analysis**
-   **Uninterrupted workflows** - scientific coding languages like Python or R allow you to run almost any kind of analysis in one scripted workflow
    -   GIS, phylogenetics, multivariate or Bayesian statistics, etc
    -   saves you manually exporting and importing data between softwares
-   Most coding languages are **open source** (e.g. R, Python, JavaScript, etc)
    -   **Free!** No one has to pay to reuse any code you share
    -   **Transparent** - You (and others) can check the background code and functions you're using, not just the software company
    -   A **culture of sharing** code (online forums, with publications, etc)

## Some coding rules {.smaller background-color="#c2c190"}

It'seasytowritemessyindecipherablecode!!! - ***Write code for people, not computers!!!***

<br>

Check out the [Tidyverse style guide](https://style.tidyverse.org/index.html) for R-specific guidance, but here are some basics:

-   use consistent, meaningful and distinct **names** for variables and functions
-   use consistent code and **formatting style** - indents, spaces, line-breaks, etc
-   **modularize code** into manageable steps/chunks
    -   or separate scripts that can be called in order from a master script or Makefile
    -   write **functions** rather than repeating the same code
-   use **commenting** to explain what you're doing at each step or in each function
    -   "notebooks" like RMarkdown, Quarto, Jupyter or Sweave allow embedded code, simplifying documentation, master/Makefiles, etc and can be used to write manuscripts, presentations or websites (e.g. all my teaching materials)
-   **check for mistakes** at every step!!! Do the outputs make sense?

## Some coding rules continued... {.smaller background-color="#c2c190"}

-   start with a "**recipe**"
    -   outline the steps/modules before you start coding to keep you on track
    -   e.g. a common recipe in R (using commented headers):

```{r, echo = T}
#Header indicating purpose, author, date, version etc

#Define settings and load required libraries

#Read in data

#Wrangle/reformat/clean/summarize data as required

#Run analyses (often multiple steps)

#Wrangle/reformat/summarize analysis outputs for visualization

#Visualize outputs as figures or tables
```

-   avoid proprietary formats! i.e. use **open source** scripting languages and file formats
-   use version control!!!

## Version control {.smaller background-color="#c2c190"}

Version control tools can be challenging , but also hugely simplify your workflow!

The advantages of version control[^3_reproducibility-2]:

[^3_reproducibility-2]: We'll use Git and [GitHub](https://github.com/), but most have similar functions. You can look up `technical terms` [here](https://docs.github.com/en/get-started/quickstart).

-   They generally help project management, especially **collaborations**
-   They allow **easy code sharing** with collaborators or the public at large - through `repositories` ("repos") or `gists` (code snippets)
-   The **system is online**, but you **can also work offline** by `cloning` the repo to your local PC. You can "`push` to" or "`pull` from" the online repo to keep versions in sync.
-   **Changes are tracked and reversible** through `commits`
    -   Any changes in a repo must be `commit`ed with a `commit message`. Each `commit` is a recoverable `version` that can be `compared` or `reverted` to
    -   This is **the essence of version control** and magically frees you from duplicated files!

## Version control continued... {.smaller background-color="#c2c190"}

-   Users can easily **adapt or build on each others' code** by `forking` repos and working on their own `branch`.
    -   This allows you to **repeat/replicate analyses** or even build websites (like this one!)
-   Collaborators can **propose changes** via `pull requests`
    -   Repo `owners` can **accept and integrate changes seamlessly** by `review` and `merge` the *forked branch* back to the `main` branch
    -   Comments associated with `commit` or `pull request`s provide a **written record of changes** and track the user, date, time, etc - all of which and are useful tracking mistakes and `blaming` when things go wrong
-   You can `assign`, log and track `issues` and `feature requests`

This should all make more sense after the practical, but here are some pretty pictures to drive some of this home...

## Version control {.smaller background-color="#c2c190"}

![Artwork by \@allison_horst [CC-BY-4.0](https://github.com/allisonhorst/stats-illustrations/blob/main/license)](img/git_commit.png)

## Version control {.smaller background-color="#c2c190"}

![Artwork by \@allison_horst [CC-BY-4.0](https://github.com/allisonhorst/stats-illustrations/blob/main/license)](img/git_navigate.png)

## 4. Computing environment {.smaller background-color="#33431e"}

Sharing your code and data is not enough to maintain reproducibility...

***Software and hardware change with upgrades, versions or user community preferences!***

-   You'll all know MicroSoft Excel, but have you heard of Quattro Pro or Lotus that were the preferred spreadsheet software of yesteryear?

The ***simple solution*** is to **carefully document the hardware and versions of software** used so that others can recreate that computing environment if needed.

-   In R, you can simply run the `sessionInfo()` function, giving details like so:

```{r}
sessionInfo()
```

## 4. Computing environment cont. {.smaller background-color="#33431e"}

<br>

### Containers

A ***better solution*** is to use **containers** like [docker](https://www.docker.com/) or [singularity](https://sylabs.io/singularity/).

<br>

These are contained, lightweight computing environments similar to [virtual machines](https://en.wikipedia.org/wiki/Virtual_machine), that you can package with your software/workflow.

<br>

You set your container up to have everything you need to run your workflow (and nothing extra), so anyone can download (or clone) your container, code and data and run your analyses perfectly every time.

<br>

## 5. Sharing data, code, publication etc {.smaller background-color="#33431e"}

::: columns
::: {.column width="50%"}
This is covered in more detail in the data management section, but suffice to say there's no point working reproducibly if you're not going to share all the components necessary to complete your workflow...

<br>

Another key component here is that ideally all your data, code, publication etc are shared *Open Access* 

- not stuck behind some paywall!
- shared with a permissable use license
    - e.g. [Creative Commons](https://creativecommons.org/licenses/)
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
![A 3-step, 10-point checklist to guide researchers toward greater reproducibility [@Alston2021].](img/alstonreproducibility.jpg)
:::
:::

## References {.smaller background-color="#33431e"}
